{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea94ff73-d156-48d3-8cb2-80aad5b60c2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Get Started with Databricks for Machine Learning\n",
    "\n",
    "In this course, you will learn basic skills that will allow you to use the Databricks Data Intelligence Platform to perform a simple data science and machine learning workflow. You will be given a tour of the workspace, and you will be shown how to work with notebooks. You will train a baseline model with AutoML and transition the best model to production. Finally, the course will also introduce you to MLflow, feature store, and workflows, and demonstrate how to train and manage an end-to-end machine learning lifecycle.\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "The content was developed for participants with these skills/knowledge/abilities:  \n",
    "- A beginner-level understanding of Python.\n",
    "- Basic understanding of DS/ML concepts (e.g. classification and regression models), common model metrics (e.g. F1-score), and Python libraries (e.g. scikit-learn and XGBoost). \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d4c56ef-2187-4385-948b-0f00b1c817e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b755208b-c6c3-4dce-aabc-0320ec8c5c9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b37a23e5-dbb2-42a3-ae26-3121253dcfe3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U databricks-sdk -qqq --upgrade\n",
    "%pip install -U databricks-feature-engineering -qqq --upgrade\n",
    "%pip install -U scikit-learn -qqq --upgrade\n",
    "%pip install -U hyperopt -qqq --upgrade\n",
    "%pip install -U mlflow==2.20.0 -qqq --upgrade\n",
    "%pip install -U pmdarima==2.0.4 -qqq --upgrade\n",
    "%pip install -U pandas==1.5.3 -qqq --upgrade\n",
    "%pip install -U category_encoders==2.6.3 -qqq --upgrade\n",
    "%pip install -U databricks-automl-runtime==0.2.20.11 -qqq --upgrade\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23f7f7f1-ec65-4962-a447-8bb81a345c2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Import libraries and functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fab0d36-7cd6-4f4a-95c7-c59550e19497",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.ensemble\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, SparkTrials, Trials, STATUS_OK\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.tracking.client import MlflowClient\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "\n",
    "fe = FeatureEngineeringClient()\n",
    "w = WorkspaceClient()\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0254fbc4-4cfd-4b42-a629-28fdf9899177",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Set default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "031de3c0-8923-4d61-b155-5c78a5420d55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "current_catalog = spark.sql(\"SELECT current_catalog()\").collect()[0][0]\n",
    "current_schema = spark.sql(\"SELECT current_schema()\").collect()[0][0]\n",
    "current_username = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "\n",
    "workspace_url = f\"https://{spark.conf.get('spark.databricks.workspaceUrl')}\"\n",
    "table_name = \"wine_quality\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9eec0961-4041-453f-914f-ff10f813cb6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create the dataset\n",
    "\n",
    "This dataset includes chemical properties like pH levels and alcohol content, used to predict wine q%md \n",
    "\n",
    "The dataset is available in `databricks-datasets`. \n",
    "\n",
    "In the following cell, you read the data in from `.csv` files into Spark DataFrames. \n",
    "\n",
    "You then write the DataFrames to tables in Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c30bd51-645b-4dcf-be04-8c9e8d385287",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id, col, lit, concat, to_date\n",
    "\n",
    "wine_quality_white = spark.read.csv(\"/databricks-datasets/wine-quality/winequality-white.csv\", sep=';', header=True, inferSchema=True)\n",
    "wine_quality_red = spark.read.csv(\"/databricks-datasets/wine-quality/winequality-red.csv\", sep=';', header=True, inferSchema=True)\n",
    "\n",
    "# Remove the spaces from the column names\n",
    "for c in wine_quality_white.columns:\n",
    "    wine_quality_white = wine_quality_white.withColumnRenamed(c, c.replace(\" \", \"_\"))\n",
    "for c in wine_quality_red.columns:\n",
    "    wine_quality_red = wine_quality_red.withColumnRenamed(c, c.replace(\" \", \"_\"))\n",
    "\n",
    "wine_quality_white = wine_quality_white.withColumn(\"is_red\", lit(0.0))\n",
    "wine_quality_white = wine_quality_white.withColumn(\"id\", concat(lit('white_'), monotonically_increasing_id().cast(\"string\")))\n",
    "\n",
    "wine_quality_red = wine_quality_red.withColumn(\"is_red\", lit(1.0))\n",
    "wine_quality_red = wine_quality_red.withColumn(\"id\", concat(lit('red_'), monotonically_increasing_id().cast(\"string\")))\n",
    "\n",
    "# Write to tables in Unity Catalog\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {table_name}_red\")\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {table_name}_white\")\n",
    "\n",
    "wine_quality_red.write.saveAsTable(f\"{table_name}_red\")\n",
    "wine_quality_white.write.saveAsTable(f\"{table_name}_white\")\n",
    "\n",
    "wine_quality = wine_quality_red.unionAll(wine_quality_white)\n",
    "wine_quality.write.saveAsTable(table_name)\n",
    "\n",
    "spark.table(table_name).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "410d2008-df87-442b-bf0d-5f441573d99e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Exploratory Data Analysis and Feature Engineering\n",
    "\n",
    "In this lab, we’ll walk you through basic exploratory data analysis and the process of creating and storing a feature table in the Feature Store. We’ll begin by demonstrating how to load data into a Spark DataFrame, view essential statistical information, and perform visual analysis using both built-in tools and code. Next, we’ll create a feature table, showing you how to store and explore it within the Feature Store UI. By the end of this lab, you should have a foundational understanding of the key steps involved in creating a feature table for Feature Engineering.\n",
    "\n",
    "## **Learning Objectives**:\n",
    "\n",
    "_By the end of this lab, you will be able to:_\n",
    "\n",
    "\n",
    "1. **Perform Basic Exploratory Data Analysis (EDA):**\n",
    "    - Utilize Spark and Pandas to store our data as a DataFrame.\n",
    "    - Use built-in functionality to analyze data from a statistical perspective. Additionally, we will visualize the summary statistics. \n",
    "\n",
    "\n",
    "2. **Introduction to Feature Engineering with Databricks:**\n",
    "    - Create a feature table and store it in Feature Store from a PySpark DataFrame.\n",
    "    - Inspect the Feature Store table using the UI and from the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a724279e-7227-4702-99b7-58de6983820c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Perform Basic Exploratory Data Analysis (EDA)\n",
    "\n",
    "In this section, we will show how you can utilize Databricks Notebooks for exploratory analysis. This will be presented in two flavors: built-in tools and labnstrative custom code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "034298a2-627f-4585-a57c-785f92bbc1fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Read and Inspect the Dataset\n",
    "\n",
    "In this section, we will utilize a fictional dataset from a wine rating company, which includes various information from acidity to pH levels. Ideally, a data scientist or machine learning practitioner, would take this dataset and perform various feature engineering tasks in order to be able to predict the `quality` rating of the wine. \n",
    "\n",
    "The next cell will create one table: `wine_quality_table`. Let's create two different dataframes, one using Spark and another using pandas.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03e63f30-3c7d-4510-a138-b394e90ebac7",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755081434782}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.table(table_name)\n",
    "pdf = df.toPandas()\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb6bab5a-3e03-4a97-b588-d0285e16236a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Inspect Statistics: Numerical Values and Visuals\n",
    "\n",
    "Here we will exhibit different ways in which you can display and visualize descriptive statistics. \n",
    "- `dbutils.data.summarize(<spark_or_pandas_dataframe>)` - This method will separate out numerical and categorical features within your Spark or Pandas DataFrame. It also displays histograms and quartile estimates. There are various options available in the generated profile such as resizing and feature search. You can consider this a more managed approach for summarizing statistics. \n",
    "- `describe(<spark_or_pandas_dataframe>)` - This method will only return a table with the necessary information. You can recover the generated profile like that in the dbutils approach by adding a data profile. \n",
    "    - Click on the **+** icon and select **data profile**. \n",
    "- `display(<spark_or_pandas_dataframe>)` - This will return the table. From this, we can build a visual to inspect the feature variables. \n",
    "- Custom code - We can use the Pandas Dataframe along with other Python libraries to build custom visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc5ae089-e4f3-4653-ba8f-821368e1b49e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.data.summarize(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d8668af-6e41-44c3-8874-f5cfa90fa0cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Spark DataFrame\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6e001da-09ab-41ef-9749-0000ef533f56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Pandas DataFrame\n",
    "display(pdf.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "262f6e7d-5f4c-43a5-a721-ed9db40bca2f",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755081473431}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Built-in Visuals\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74d6686b-be51-42e6-bffb-08adde4ec4d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgZnVuY3Rpb25zIGFzIEYKCiMgTGV0J3MgZmluZCBRMSwgbWVkaWFuLCBhbmQgUTMgb2YgcEggZ3JvdXBlZCBieSB0aGUgcXVhbGl0eSByYW5raW5nIGZvciAKCmNvbHVtbl9zdGF0cyA9ICdwSCcKCmRpc3BsYXkoZGYuZ3JvdXBCeSgncXVhbGl0eScpLmFnZygKICAgIEYubWluKGYne2NvbHVtbl9zdGF0c30nKS5hbGlhcygnbWluJyksCiAgICBGLmV4cHIoZidwZXJjZW50aWxlKHtjb2x1bW5fc3RhdHN9LCAwLjI1KScpLmFsaWFzKCdRMScpLAogICAgRi5leHByKGYncGVyY2VudGlsZSh7Y29sdW1uX3N0YXRzfSwgMC41KScpLmFsaWFzKCdtZWRpYW4nKSwKICAgIEYuZXhwcihmJ3BlcmNlbnRpbGUoe2NvbHVtbl9zdGF0c30sIDAuNzUpJykuYWxpYXMoJ1EzJyksCiAgICBGLm1heChmJ3tjb2x1bW5fc3RhdHN9JykuYWxpYXMoJ21heCcpLAogICAgRi5jb3VudChmJ3tjb2x1bW5fc3RhdHN9JykuYWxpYXMoJ2NvdW50JykKKSk=\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView8ebfada\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView8ebfada\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView8ebfada\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView8ebfada) SELECT `quality`,`median`,`count`,`count` FROM q\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView8ebfada\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "series": {
             "column": "count",
             "id": "column_696203f82910"
            },
            "size": {
             "column": "count",
             "id": "column_696203f82911"
            },
            "x": {
             "column": "quality",
             "id": "column_696203f82905"
            },
            "y": [
             {
              "column": "median",
              "id": "column_696203f82908"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "bubble",
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "median": {
             "type": "bubble",
             "yAxis": 0
            },
            "quality": {
             "type": "bubble",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "9c9cccba-29c7-4b58-aebb-e771cc7bd9c3",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 4.833333333333335,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "selects": [
          {
           "column": "quality",
           "type": "column"
          },
          {
           "column": "median",
           "type": "column"
          },
          {
           "column": "count",
           "type": "column"
          },
          {
           "column": "count",
           "type": "column"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract additional statistics\n",
    "# Let's find Q1, median, and Q3 of pH grouped by the quality ranking for \n",
    "column_stats = 'pH'\n",
    "\n",
    "display(df.groupBy('quality').agg(\n",
    "    F.min(f'{column_stats}').alias('min'),\n",
    "    F.expr(f'percentile({column_stats}, 0.25)').alias('Q1'),\n",
    "    F.expr(f'percentile({column_stats}, 0.5)').alias('median'),\n",
    "    F.expr(f'percentile({column_stats}, 0.75)').alias('Q3'),\n",
    "    F.max(f'{column_stats}').alias('max'),\n",
    "    F.count(f'{column_stats}').alias('count')\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b2ff88c-8bef-4d59-b856-75b31a2093b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Bubble Chart Using GUI Visualization Editor\n",
    "\n",
    "We can now use the **Visualization Editor** in the Databricks UI to build a bubble chart using our grouped summary statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "717785db-ce6b-4a94-a6eb-e351a8eac918",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Steps:**\n",
    "- Create the grouped DataFrame in the following cell.\n",
    "- In the output result cell:\n",
    "   - Click the **+**  dropdown next to Table (top-right of the table display).\n",
    "   - Select **Visualization**.\n",
    "\n",
    "- In the **Visualization Editor**:\n",
    "   - Select **Bubble** as the visualization type.\n",
    "   - Under **X column**, select `quality`.\n",
    "   - Under **Y columns**, select `median_pH`.\n",
    "   - Under **Group by**, select `count`,\n",
    "   - Under **Bubble size column**, select `count`.\n",
    "   - Under **Bubble size coefficient**, check if it's `1`,\n",
    "   - Leave **Bubble size proportional to** as `Diameter`.\n",
    "\n",
    "- Click **Save** to render the chart.\n",
    "\n",
    "This creates a bubble chart that shows:\n",
    "- Wine **quality** on the x-axis.\n",
    "- **Median pH** level on the y-axis.\n",
    "- **Bubble size** proportional to the number of samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9ca6adc-e03e-4de8-94ba-5272f5639349",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, count\n",
    "\n",
    "grouped_df = df.groupBy(\"quality\").agg(expr(\"percentile(pH, 0.5)\").alias(\"median_pH\"), count(\"pH\").alias(\"count\"))\n",
    "display(grouped_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34de3798-6106-4562-99b0-48d38f166173",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Introduction to Feature Engineering on Databricks\n",
    "\n",
    "After exploring our data for a bit, we see that it would be beneficial to be able to predict `quality`. There are many things we can do to this dataset, such as outlier analysis, etc. Instead, since this is just an introductory lab, let's keep it simple and add an additional feature that separates out low, average, and high `pH`. This will add an additional feature to the data we already have. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f61a0f72-7b9f-4a14-95f2-29c496408e0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Business Logic\n",
    "\n",
    "Based on our analysis above, suppose business stakeholders give you the following guidelines for pH levels.\n",
    "\n",
    "- Low pH: >= Q1\n",
    "- Average pH: < Q1 and < Q3\n",
    "- High pH: >= Q3\n",
    "\n",
    "Let's take this business logic and create a new **feature** and store it in a feature table in our Feature Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0da82ec-d199-45de-82f5-42babb3c8136",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feature_variables = ['fixed_acidity',\n",
    "                     'volatile_acidity',\n",
    "                     'citric_acid',\n",
    "                     'pH',\n",
    "                     'sulphates',\n",
    "                     'alcohol',\n",
    "                     'quality',\n",
    "                     'is_red']\n",
    "prediction_variable = 'quality'\n",
    "primary_key = ['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "245a326c-c94b-4b94-b9ec-dbd8554cb713",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755162392110}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feature_df = df.select(primary_key + feature_variables)\n",
    "display(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cfbd20a-6461-48a7-862d-5ec6f3f202e7",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755162407308}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr, when\n",
    "\n",
    "quantiles = feature_df.approxQuantile(\"pH\", [0.25, 0.75], 0.0)\n",
    "\n",
    "Q1, Q3 = quantiles\n",
    "\n",
    "wine_feature_df = feature_df.withColumn(\n",
    "    \"pHCategory\",\n",
    "    when(col(\"pH\") <= Q1, \"Low\")\n",
    "    .when((col(\"pH\") > Q1) & (col(\"pH\") < Q3), \"Average\")\n",
    "    .otherwise(\"High\")\n",
    ")\n",
    "\n",
    "display(wine_feature_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66db8556-0323-4fbe-a3d4-2a3ea2f087fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Save features to feature table\n",
    "\n",
    "Now that we have our feature store created, let's store it as a feature table within Feature Store. We have all the ingredients we need to do this within Databricks Unity Catalog: \n",
    "- Feature table (Spark DataFrame)\n",
    "- Primary key (designated feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61e443dc-a2d2-4a79-94c3-ed28b6764370",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set the feature table name for storage in UC\n",
    "feature_table_name = f'{table_name}_features'\n",
    "\n",
    "# drop the table if it exists\n",
    "try:\n",
    "    fe.drop_table(\n",
    "        name = feature_table_name,\n",
    "    )\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Create the feature table\n",
    "fe.create_table(\n",
    "    name = feature_table_name,\n",
    "    primary_keys = primary_key,\n",
    "    df = wine_feature_df, \n",
    "    description=\"Wine quality features\", \n",
    "    tags = {\"source\": \"bronze\", \"format\": \"delta\"}\n",
    ")\n",
    "\n",
    "print(f\"The name of the feature table: {feature_table_name} url: {workspace_url}/explore/data/{current_catalog}/{current_schema}/{feature_table_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba96944a-0f3f-42d9-b6f7-634e5ba4bd42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now, go inspect your feature table using the UI with the URL provided in the previous cell output!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0359f2a-8143-4694-9237-38086d9fde20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Build your first machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aff261d0-e3b8-4c59-be3c-d52d2538d8cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Binary Classification\n",
    "\n",
    "This example illustrates how to train a machine learning classification model on Databricks. Databricks Runtime for Machine Learning comes with many libraries pre-installed, including scikit-learn for training and pre-processing algorithms, MLflow to track the model development process, and Hyperopt with SparkTrials to scale hyperparameter tuning.\n",
    "\n",
    "With the Databricks Free Edition, as only Serverless compute is avaiilable, it is not possible to optimize and use the SparkTrials, and therefore, you will leverage the Trials library instead.\n",
    "\n",
    "In this notebook, you create a classification model to predict whether a wine is considered \"high-quality\". The dataset[1] consists of 11 features of different wines (for example, alcohol content, acidity, and residual sugar) and a quality ranking between 1 to 10. \n",
    "\n",
    "This tutorial covers:\n",
    "- Train a classification model with MLflow tracking\n",
    "- Hyperparameter tuning to improve model performance\n",
    "- Save results and models to Unity Catalog\n",
    "\n",
    "For more details on productionizing machine learning on Databricks including model lifecycle management and model inference, see the ML End to End Example ([AWS](https://docs.databricks.com/mlflow/end-to-end-example.html) | [Azure](https://learn.microsoft.com/azure/databricks/mlflow/end-to-end-example) | [GCP](https://docs.gcp.databricks.com/mlflow/end-to-end-example.html)).\n",
    "\n",
    "By default, the MLflow Python client creates models in the Databricks workspace model registry. To save models in Unity Catalog, configure the MLflow client as shown in the following cell.\n",
    "\n",
    "[1] The example uses a dataset from the UCI Machine Learning Repository, presented in [*Modeling wine preferences by data mining from physicochemical properties*](https://www.sciencedirect.com/science/article/pii/S0167923609001377?via%3Dihub) [Cortez et al., 2009].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "044dece8-4351-4743-9dc2-1d3054f2a6ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Preprocess data\n",
    "\n",
    "Here we will build a dataset to predict if the wine is 'red' or 'white'.\n",
    "We also need to map the 'pHCategory' attribute to a numerical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9f85182-0cf7-43a3-827d-bc304e913c4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load data from Unity Catalog as Pandas dataframes\n",
    "training_df = spark.read.format('delta').table(f'{table_name}_features').toPandas()\n",
    "\n",
    "# Define the pHCategory mapping to map it back to numbers instead of strings\n",
    "mapping = {'Low': 0.0, 'Average': 1.0, 'High': 2.0}\n",
    "\n",
    "# Apply the mapping to the 'pHCategory' column\n",
    "training_df['pHCategory'] = training_df['pHCategory'].map(mapping)\n",
    "\n",
    "# Use the training dataset to store variables X, the features, and y, the target variable. \n",
    "X = training_df.drop(columns = ['id', \"is_red\"])\n",
    "y = training_df[\"is_red\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "  X, \n",
    "  y, \n",
    "  test_size=0.2, \n",
    "  random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb5f8c63-0402-43f6-af92-1e09ca36728b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Train with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "239f5b08-9ce3-4f98-ab41-f5d07a6ed0be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Enable MLflow autologging for this notebook\n",
    "mlflow.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c008ba33-44d8-4f8a-9988-7e3694c388a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Next, train a classifier within the context of an MLflow run, which automatically logs the trained model and many associated metrics and parameters. \n",
    "\n",
    "You can supplement the logging with additional metrics such as the model's AUC score on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b22344b5-fe12-47cf-b712-cd131de39245",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name='gradient_boost') as run:\n",
    "    # Initialize the GradientBoosting classifier\n",
    "    model = sklearn.ensemble.GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "    # Fit the model on the training data. Models, parameters, and training metrics are tracked automatically\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    predicted_probs = model.predict_proba(X_test)\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(y_test, predicted_probs[:,1])\n",
    "    roc_curve = sklearn.metrics.RocCurveDisplay.from_estimator(model, X_test, y_test)\n",
    "    \n",
    "    # Save the ROC curve plot to a file\n",
    "    roc_curve.figure_.savefig(\"roc_curve.png\")\n",
    "    \n",
    "    # The AUC score on test data is not automatically logged, so log it manually\n",
    "    mlflow.log_metric(\"test_auc\", roc_auc)\n",
    "    \n",
    "    # Log the ROC curve image file as an artifact\n",
    "    mlflow.log_artifact(\"roc_curve.png\")\n",
    "    \n",
    "    print(\"Test AUC of: {}\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c780789c-fae5-41d5-9a42-7859a8751673",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### View MLflow runs\n",
    "\n",
    "To view the logged training run, click the **Experiment** icon <img src=\"https://docs.databricks.com/_static/images/mlflow/quickstart/experiment-icon.png\"/> at the upper right of the notebook to display the experiment sidebar. If necessary, click the refresh icon to fetch and monitor the latest runs. \n",
    "\n",
    "<img src=\"https://docs.databricks.com/_static/images/mlflow/quickstart/experiment-sidebar-icons.png\"/>\n",
    "\n",
    "To display the more detailed MLflow experiment page, click the experiment page icon. This page allows you to compare runs and view details for specific runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ef441b0-f76b-4344-9116-75b0f40bdb05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load a model and make predictions\n",
    "You can also access the results for a specific run using the MLflow API. The code in the following cell illustrates how to load the model trained in a given MLflow run and use it to make predictions. You can also find code snippets for loading specific models on the MLflow run page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "424b1d60-4c80-4ac3-8141-a39bfff60aa0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# After a model has been logged, you can load it in different notebooks or jobs\n",
    "# mlflow.pyfunc.load_model makes model prediction available under a common API\n",
    "model_loaded = mlflow.pyfunc.load_model(\n",
    "  'runs:/{run_id}/model'.format(\n",
    "    run_id=run.info.run_id\n",
    "  )\n",
    ")\n",
    "\n",
    "predictions_loaded = model_loaded.predict(X_test)\n",
    "predictions_original = model.predict(X_test)\n",
    "\n",
    "# The loaded model should match the original\n",
    "assert(np.array_equal(predictions_loaded, predictions_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed1ea92a-37ed-48fb-96d9-1a024f2ee7ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "test_df = spark.createDataFrame([\n",
    "    Row(\n",
    "        fixed_acidity=6.2, \n",
    "        volatile_acidity=0.66, \n",
    "        citric_acid=0.48, \n",
    "        pH=3.33, \n",
    "        sulphates=0.39, \n",
    "        alcohol=12.8, \n",
    "        quality=8, \n",
    "        pHCategory=0.0\n",
    "        # it's a white wine\n",
    "    ),\n",
    "    Row(\n",
    "        fixed_acidity=6.6, \n",
    "        volatile_acidity=0.725, \n",
    "        citric_acid=0.2, \n",
    "        pH=3.29, \n",
    "        sulphates=0.54, \n",
    "        alcohol=9.2, \n",
    "        quality=6, \n",
    "        pHCategory=1.0\n",
    "        # it's a red wine\n",
    "    )\n",
    "]).toPandas()\n",
    "test_df = test_df.astype({col: 'int32' for col in test_df.select_dtypes('int64').columns})\n",
    "\n",
    "test_predictions = model_loaded.predict(test_df)\n",
    "display(test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb08c336-9636-4d0f-8827-66d3807b873e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Hyperparameter tuning with Hyperopt\n",
    "At this point, you have trained a simple model and used the MLflow tracking service to organize your work. Next, you can perform more sophisticated tuning using Hyperopt.\n",
    "\n",
    "[Hyperopt](http://hyperopt.github.io/hyperopt/) is a Python library for hyperparameter tuning. For more information about using Hyperopt in Databricks, see the documentation ([AWS](https://docs.databricks.com/applications/machine-learning/automl-hyperparam-tuning/index.html#hyperparameter-tuning-with-hyperopt) | [Azure](https://docs.microsoft.com/azure/databricks/applications/machine-learning/automl-hyperparam-tuning/index#hyperparameter-tuning-with-hyperopt) | [GCP](https://docs.gcp.databricks.com/applications/machine-learning/automl-hyperparam-tuning/index.html#hyperparameter-tuning-with-hyperopt)).\n",
    "\n",
    "You can use Hyperopt to run hyperparameter sweeps and train multiple models in parallel. This reduces the time required to optimize model performance. MLflow tracking is integrated with Hyperopt to automatically log models and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fafaaee7-94db-4767-babd-c39fde0a2e9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the search space to explore\n",
    "search_space = {\n",
    "  'n_estimators': scope.int(hp.quniform('n_estimators', 20, 1000, 1)),\n",
    "  'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "  'max_depth': scope.int(hp.quniform('max_depth', 2, 5, 1)),\n",
    "}\n",
    "\n",
    "def train_model(params):\n",
    "  # Enable autologging on each worker\n",
    "  mlflow.autolog()\n",
    "  with mlflow.start_run(nested=True):\n",
    "    model_hp = sklearn.ensemble.GradientBoostingClassifier(\n",
    "      random_state=0,\n",
    "      **params\n",
    "    )\n",
    "    model_hp.fit(X_train, y_train)\n",
    "    predicted_probs = model_hp.predict_proba(X_test)\n",
    "    # Tune based on the test AUC\n",
    "    # In production, you could use a separate validation set instead\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(y_test, predicted_probs[:,1])\n",
    "    mlflow.log_metric('test_auc', roc_auc)\n",
    "    \n",
    "    # Set the loss to -1*auc_score so fmin maximizes the auc_score\n",
    "    return {'status': STATUS_OK, 'loss': -1*roc_auc}\n",
    "\n",
    "# SparkTrials distributes the tuning using Spark workers\n",
    "# Greater parallelism speeds processing, but each hyperparameter trial has less information from other trials\n",
    "# On smaller clusters try setting parallelism=2\n",
    "# spark_trials = SparkTrials(\n",
    "#   parallelism=1\n",
    "# )\n",
    "# As we only have access to Serverless compute, we will leverage the Trials class instead\n",
    "spark_trials = Trials(\n",
    "  # parallelism=1\n",
    ")\n",
    "\n",
    "with mlflow.start_run(run_name='gb_hyperopt') as run:\n",
    "  # Use hyperopt to find the parameters yielding the highest AUC\n",
    "  best_params = fmin(\n",
    "    fn=train_model, \n",
    "    space=search_space, \n",
    "    algo=tpe.suggest, \n",
    "    max_evals=32,\n",
    "    trials=spark_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cff801e-1087-4fa6-9d3a-b8c5076650a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### Search runs to retrieve the best model\n",
    "\n",
    "Because all of the runs are tracked by MLflow, you can retrieve the metrics and parameters for the best run using the MLflow search runs API to find the tuning run with the highest test auc.\n",
    "\n",
    "This tuned model should perform better than the simpler models trained in the earlier section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "650139ba-a9e6-4d74-87af-8158ed9bf061",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sort runs by their test auc. In case of ties, use the most recent run.\n",
    "best_run = mlflow.search_runs(\n",
    "  order_by=['metrics.test_auc DESC', 'start_time DESC'],\n",
    "  max_results=10,\n",
    ").iloc[0]\n",
    "print('Best Run')\n",
    "print('AUC: {}'.format(best_run[\"metrics.test_auc\"]))\n",
    "print('Num Estimators: {}'.format(best_run[\"params.n_estimators\"]))\n",
    "print('Max Depth: {}'.format(best_run[\"params.max_depth\"]))\n",
    "print('Learning Rate: {}'.format(best_run[\"params.learning_rate\"]))\n",
    "\n",
    "best_model_pyfunc = mlflow.pyfunc.load_model(\n",
    "  'runs:/{run_id}/model'.format(\n",
    "    run_id=best_run.run_id\n",
    "  )\n",
    ")\n",
    "\n",
    "# Make a dataset with all predictions\n",
    "best_model_predictions = X_test\n",
    "best_model_predictions[\"prediction\"] = best_model_pyfunc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c045e102-ae9e-4253-a9f4-842a1b754549",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### Get the results and Save the models to Unity Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c331374-437d-4a90-af21-75e01cc5c387",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predictions_table = f\"{table_name}_predictions\"\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {predictions_table}\")\n",
    "\n",
    "results = spark.createDataFrame(best_model_predictions)\n",
    "\n",
    "# Write results back to Unity Catalog from Python\n",
    "results.write.saveAsTable(f\"{predictions_table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d4c1639-3859-4855-8496-2f788c95e0f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_uri = 'runs:/{run_id}/model'.format(\n",
    "    run_id=best_run.run_id\n",
    ")\n",
    "\n",
    "mlflow.register_model(model_uri, f\"{table_name}_model_is_red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ba781df-1c09-4540-97b2-5d4c316acc1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Multi-class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b094915c-b6a7-4825-b5d2-9076f9a201da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Preprocess data\n",
    "\n",
    "Here, you will predict the wine quality which is a numercal discrete value via a multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3a79b63-688a-48a9-950d-ba247ca525e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the feature table\n",
    "training_df = spark.read.format('delta').table(f'{table_name}_features').toPandas()\n",
    "\n",
    "# Define the mapping\n",
    "mapping = {'Low': 0.0, 'Average': 1.0, 'High': 2.0}\n",
    "\n",
    "# Apply the mapping to the 'pHCategory' column\n",
    "training_df['pHCategory'] = training_df['pHCategory'].map(mapping)\n",
    "# Use the training dataset to store variables X, the features, and y, the target variable. \n",
    "X = training_df.drop(columns = [\"id\", \"quality\"])\n",
    "y = training_df[\"quality\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "  X, \n",
    "  y, \n",
    "  test_size=0.2, \n",
    "  random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "849636f7-ca3c-4985-91b8-96e4e93b7b30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Train with Random Forest\n",
    "\n",
    "Now that we have our training set ready to go, the next step is to train a model using the `sklearn` library. We will build a random forest classification model, tracking the F1-score for a single run. We will initiate the tracking before creating the model using `mlflow.start_run()` as the context manager. Within this manager we will:\n",
    "\n",
    "- Initialize the random forest classifier\n",
    "- Fit the model\n",
    "\n",
    "Make a prediction using our test set\n",
    "\n",
    "- Log the F1-score metric as `test_f1`\n",
    "- Capture the artifacts for model tracking and management using the flavor `mlflow.sklearn`. *Flavor* in this context simply means that MLflow will package our scikit-learn model in a consistent and standardized way. If we wished to use a different ML library, we would use a different *flavor*.\n",
    "\n",
    "Finally, we will register the model to Unity Catalog. Note, Databricks does not recommend registering your model at the Workspace level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dedca41-de47-4393-9bd8-33eaa2a650c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# set the path for mlflow experiment\n",
    "exp = mlflow.set_experiment(f\"/Users/{w.current_user.me().user_name}/get-started-with-ml-flow-experiment\")\n",
    "\n",
    "print(f\"The experiment {exp.experiment_id} is accessible at the url: {workspace_url}/ml/experiments/{exp.experiment_id}\")\n",
    "\n",
    "with mlflow.start_run(run_name = 'get-started-with-ml-flow-run') as run:  \n",
    "    # Initialize the Random Forest classifier\n",
    "    rf_classifier = sklearn.ensemble.RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    # Enable automatic logging of input samples, metrics, parameters, and models\n",
    "    mlflow.sklearn.autolog(\n",
    "        log_input_examples = True,\n",
    "        silent = True\n",
    "    )\n",
    "    # Calculate F1 score with 'macro' averaging for multiclass\n",
    "    mlflow.log_metric(\"test_f1\", sklearn.metrics.f1_score(y_test, y_pred, average='macro'))\n",
    "    # mlflow.log_metric(\"test_f1\", sklearn.metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "    print(f\"The experiment run {run.info.run_id} is accessible at the url: {workspace_url}/ml/experiments/{exp.experiment_id}/runs/{run.info.run_id}\")\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    mlflow.sklearn.log_model(\n",
    "        rf_classifier,\n",
    "        name = \"model-artifacts\", \n",
    "        input_example=X_train[:3],\n",
    "        signature=infer_signature(X_train, y_train)\n",
    "    )\n",
    "\n",
    "    model_uri = f\"runs:/{run.info.run_id}/model-artifacts\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c567699-02e8-4bb3-b784-cc82f0c5c759",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Modify the registry uri to point to Unity Catalog\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Define the model name \n",
    "model_name = f\"{table_name}\"\n",
    "\n",
    "# Register the model in the model registry\n",
    "registered_model = mlflow.register_model(model_uri=model_uri, name=f\"{table_name}_model_quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "345d3ffc-9967-41d7-b7ef-7529bf3a46b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Notice that you will now have an additional version under your model. \n",
    "\n",
    "Navigate to your model in Catalog explorer. You will find version 1 (created during the classroom setup with alias **staging**) and version 2, which you must created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32b15421-ff0c-40e9-b6bc-2b740ea729cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize an MLflow Client\n",
    "client = MlflowClient()\n",
    "\n",
    "# Assign a \"dev\" alias to model version 1\n",
    "client.set_registered_model_alias(\n",
    "    name= registered_model.name,  # The registered model name\n",
    "    alias=\"dev\",  # The alias representing the dev environment\n",
    "    version=registered_model.version  # The version of the model you want to move to \"dev\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "916da103-e57b-472a-8f2e-10a1977aca05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2bbe48d4-60b7-42c4-8517-4bf81a282b10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Build your first machine learning model - Lab\n",
    "\n",
    "In this lab, we will construct a comprehensive ML model pipeline using Databricks. Initially, we will train and monitor our model using mlflow. Subsequently, we will register the model and advance it to the next stage. In the latter part of the lab, we will utilize Model Serving to deploy the registered model. Following deployment, we will interact with the model via a REST endpoint and examine its behavior through an integrated monitoring dashboard.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad8a2b1a-32e3-49ea-85e4-ec11078da994",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Data Ingestion\n",
    "\n",
    "The first step in this lab is to ingest data from .csv files and save them as delta tables. \n",
    "\n",
    "Navigate to the Catalog explorer and locate the datasets under shared and find `databricks_airbnb_sample_data`. \n",
    "\n",
    "Expand `v01` and locate `airbnb-cleaned-mlflow.csv` located in the volume `sf-listings`. \n",
    "\n",
    "Second, we grab a few relevant features to help train our model to predict the target variable for this dataset, `price`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41926893-3f65-43e2-ac17-8f74ea17ea0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Copy and paste the location of the airbnb dataset\n",
    "file_path = '<FILL_IN>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f95a5ab8-fef4-4001-b289-d1393365d2dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Read in the csv file and store it in Unity Catalog within the catalog and schema shown in cell 8. \n",
    "## Name your delta table \"airbnb_lab\"\n",
    "my_table = <FILL_IN>\n",
    "df = spark.read.format(<FILL_IN>).option(\"header\", \"true\").load(<FILL_IN>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bda02bdb-0ef6-4db6-bdc2-48742dda0041",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's preprocess this dataset since the schema shows all variables being of time `string`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16296d8d-e89e-47e3-9cb9-dcf444d17235",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import FloatType, IntegerType, StringType\n",
    "\n",
    "## Specify columns that should be treated as categorical (e.g., integers in categorical context)\n",
    "categorical_columns = ['neighbourhood_cleansed', 'zipcode', 'property_type', 'room_type', 'bed_type']\n",
    "for col in categorical_columns:\n",
    "    df = df.withColumn(col, df[col].cast(StringType()))\n",
    "\n",
    "## Specify columns that should remain as floats for machine learning\n",
    "numerical_columns = ['host_total_listings_count', 'latitude', 'longitude', 'accommodates', 'bathrooms', \n",
    "                 'bedrooms', 'beds', 'minimum_nights', 'number_of_reviews', 'review_scores_rating',\n",
    "                 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin',\n",
    "                 'review_scores_communication', 'review_scores_location', 'review_scores_value', 'price']\n",
    "for col in numerical_columns:\n",
    "    df = df.withColumn(col, df[col].cast(FloatType()))\n",
    "\n",
    "df = df.withColumn(\"airbnb_id\", F.monotonically_increasing_id()).select(['airbnb_id'] + numerical_columns + categorical_columns)\n",
    "\n",
    "## Check the schema to confirm data type changes\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d37e439-29ca-4198-9cf9-cce7c007587b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.write.format('delta').mode('overwrite').saveAsTable('airbnb_lab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f5640bb-80e7-48ab-ab40-1cee41d92f49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68fa1cce-f076-41db-96ec-5a64850c4379",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Next, using PySpark, create a DataFrame called `feature_df` that is the feature table. Recall that the feature table must contain a primary key and does not contain the target variable, which is `price` in our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82529665-53d2-4eaa-b2bb-28f11efaae93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feature_df = df.select(<FILL_IN>)\n",
    "\n",
    "## Find rooms with a score of at least 6.0 and 80 reviews\n",
    "feature_df = feature_df.filter((<FILL_IN>) & (<FILL_IN>))\n",
    "display(feature_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f12f87f2-f784-40dd-9d78-6237407eb80b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Write to Databricks Feature Store. Remember, we do not include our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "551417d8-518b-4008-bad4-cf6d88ec6a75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Write feature_df to Databricks Feature Store. \n",
    "from databricks.feature_store import FeatureStoreClient\n",
    "\n",
    "fs = FeatureStoreClient()\n",
    "\n",
    "feature_df = feature_df.drop(<FILL_IN>)\n",
    "\n",
    "fs.create_table(\n",
    "    name=\"airbnb_features\",\n",
    "    primary_keys = <FILL_IN>, \n",
    "    df = <FILL_IN>,\n",
    "    description = \"This is the airbnb feature table\",\n",
    "    tags = {\"source\": \"bronze\", \"format\": \"delta\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8842365-fdca-4f7a-bc3c-9ddc9cc91c32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Train a Model\n",
    "To summarize what you have accomplished so far:\n",
    "1. You have created a table that is a snapshot of the original dataset (Airbnb csv file) called `airbnb_lab`.\n",
    "1. You have created a feature table and stored it in Databricks Feature Store called `airbnb_features`.\n",
    "\n",
    "Next, we will simulate the process of reading in these Delta tables and training a model. We will train a machine learning model and register it to Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c11561ba-6df5-4701-82bf-d7609b1929cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Read in the feature table airbnb_features from Unity Catalog using PySpark and store it as training_df\n",
    "prediction_df = spark.read.format('delta').table(<FILL_IN>).select(<FILL_IN>)\n",
    "features_df = spark.read.format('delta').table(<FILL_IN>)  \n",
    "\n",
    "## Join these two dataframes on airbnb_id\n",
    "training_df = prediction_df.join(<FILL_IN>, on='airbnb_id').toPandas()\n",
    "\n",
    "## Perform train-test split\n",
    "X = training_df.drop(columns = [<FILL_IN>])\n",
    "y = training_df[<FILL_IN>]\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(<FILL_IN>, <FILL_IN>, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebd5f965-be9b-4800-b098-f91764549769",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Set the path for mlflow experiment\n",
    "mlflow.set_experiment(f\"/Users/{DA.username}/<FILL_IN>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc844959-b4e6-4371-9a5a-cc9e7b780742",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Start the MLflow run\n",
    "with mlflow.start_run(run_name=<FILL_IN>) as run:\n",
    "    ## Initialize the Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=<FILL_IN>, random_state=42)\n",
    "\n",
    "    ## Fit the model on the training data\n",
    "    rf_classifier.fit(<FILL_IN>, <FILL_IN>)\n",
    "\n",
    "    ## Make predictions on the test data\n",
    "    y_pred = rf_classifier.predict(<FILL_IN>)\n",
    "\n",
    "    ## Enable automatic logging of input samples, metrics, parameters, and models\n",
    "    mlflow.sklearn.autolog(log_input_examples=<FILL_IN>, silent=True)\n",
    "    ## Calculate F1 score with 'macro' averaging for multiclass\n",
    "    mlflow.log_metric(\"test_f1\", f1_score(<FILL_IN>, <FILL_IN>, average=\"macro\"))\n",
    "    ## mlflow.log_metric(\"test_f1\", f1_score(y_test, y_pred))\n",
    "\n",
    "    mlflow.sklearn.log_model(\n",
    "        rf_classifier,\n",
    "        artifact_path=\"model-artifacts\",\n",
    "        input_example=X_train[:3],\n",
    "        signature=infer_signature(<FILL_IN>, <FILL_IN>),\n",
    "    )\n",
    "\n",
    "    model_uri = f\"runs:/{run.info.run_id}/model-artifacts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f51a9fcf-8a8f-4d2e-bebf-76a7b103549f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "In this lab, we explored the full potential of Databricks Data Intelligence Platform for machine learning tasks. \n",
    "\n",
    "From data ingestion to model deployment, we covered essential steps such as data preparation, model training, tracking, registration, and serving. \n",
    "\n",
    "By utilizing MLflow for model tracking and management, and Model Serving for deployment, we demonstrated how Databricks offers a seamless Lakeflow Jobs for building and deploying ML models. \n",
    "\n",
    "Through this comprehensive lab, users can gain a solid understanding of Databricks capabilities for ML tasks and streamline their development process effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ce91629-dd3e-4e17-a34d-762b8be370bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Make predictions with your models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a6c7e13-25a0-4dbb-98b4-7a0bb9053827",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Local Model Serving\n",
    "\n",
    "As you did earlier, it is possible to load a model and the start prediting locally as demonstrated below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54849eb4-cfaa-4069-bbd9-4f7838361246",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_loaded = mlflow.pyfunc.load_model(\n",
    "  'runs:/{run_id}/model'.format(\n",
    "    run_id=run.info.run_id\n",
    "  )\n",
    ")\n",
    "test_df = spark.createDataFrame([\n",
    "    Row(\n",
    "        fixed_acidity=6.2, \n",
    "        volatile_acidity=0.66, \n",
    "        citric_acid=0.48, \n",
    "        pH=3.33, \n",
    "        sulphates=0.39, \n",
    "        alcohol=12.8, \n",
    "        pHCategory=0.0,\n",
    "        is_red=0.0\n",
    "        # it's a quality=8\n",
    "    ),\n",
    "    Row(\n",
    "        fixed_acidity=6.6, \n",
    "        volatile_acidity=0.725, \n",
    "        citric_acid=0.2, \n",
    "        pH=3.29, \n",
    "        sulphates=0.54, \n",
    "        alcohol=9.2, \n",
    "        pHCategory=1.0,\n",
    "        is_red=1.0\n",
    "        # it's a quality=6\n",
    "    )\n",
    "]).toPandas()\n",
    "test_df = test_df.astype({col: 'int32' for col in test_df.select_dtypes('int64').columns})\n",
    "\n",
    "test_predictions = model_loaded.predict(test_df)\n",
    "display(test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f4abda6-147b-457e-bf45-e87831a900ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Mosaic AI Model Serving\n",
    "\n",
    "In this lesson, we will focus on how to serve a registered model using **Mosaic AI Model Serving** for real-time inferencing. We’ll also introduce **Databricks Workflows** as a way to automate ML pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ec751ac-8cb8-4edb-b9fe-3ee2d99d7292",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Setting Up Model Serving\n",
    "\n",
    "We can create Model Serving endpoints with the Databricks Machine Learning API or the Databricks Machine Learning UI. \n",
    "\n",
    "An endpoint can serve any registered Python MLflow model in the **Model Registry**.\n",
    "\n",
    "In order to keep it simple, in this demo, we are going to use the Model Serving UI for creating, managing and using the Model Serving endpoints. We can create model serving endpoints with the **\"Serving\"** page UI or directly from registered **\"Models\"** page.  \n",
    "\n",
    "Let's go through the steps of creating a model serving endpoint in Models page. **You will not actually create the endpoint.**\n",
    "\n",
    "- Go to **Models**. \n",
    "\n",
    "- Select **Owned by me** at the top.\n",
    "\n",
    "- Select the model you want to serve under the **Name** column. Notice this will take you to the Catalog menu. \n",
    "\n",
    "- Click the **Serve this model** button on the top right. This will take you to the **Serving endpoints** screen.\n",
    "\n",
    "- Next in **General**, enter in a name of the form **wine_model_quality**.\n",
    "\n",
    "- Select **workspace.default.wine_quality_model_quality** as **Entity**.\n",
    "\n",
    "- There are several configurations under **Served entities** that we will not discuss here. \n",
    "\n",
    "- For **Compute scale-out**, select **small**. You can select **Scale to zero** for this lesson as well. We will be deleting the endpoint at the end of this lesson, so this doesn't matter too much for our purposes. \n",
    "\n",
    "- Click on **Create** at the bottom right. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25864ab6-56e6-4e49-9031-2d4eaafb7777",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Query Serving Endpoint\n",
    "\n",
    "Let's use the deployed model for real-time inference. Here’s a step-by-step guide for querying an endpoint in Databricks Model Serving:\n",
    "\n",
    "- Go to the **Serving** endpoints page and select the endpoint you want to query.\n",
    "\n",
    "- Click **Use** button the top right corner.\n",
    "\n",
    "There are 4 methods for querying an endpoint; **browser**, **CURL**, **Python**, and **SQL**. \n",
    "\n",
    "For now, let's use the easiest method; querying right in the **browser** window. \n",
    "\n",
    "In this method, we need to provide the input parameters in JSON format. \n",
    "\n",
    "Since we used `mlflow.sklearn.autolog()` with `log_input_examples = True`, we registered an example with MLflow, which appear automatically when selecting **browser**.\n",
    "\n",
    "- Input the following request:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"dataframe_split\": {\n",
    "    \"columns\": [\n",
    "      \"fixed_acidity\",\n",
    "      \"volatile_acidity\",\n",
    "      \"citric_acid\",\n",
    "      \"pH\",\n",
    "      \"sulphates\",\n",
    "      \"alcohol\",\n",
    "      \"pHCategory\",\n",
    "      \"is_red\"\n",
    "    ],\n",
    "    \"data\": [\n",
    "      [\n",
    "        6.2, \n",
    "        0.66, \n",
    "        0.48, \n",
    "        3.33, \n",
    "        0.39, \n",
    "        12.8, \n",
    "        0.0,\n",
    "        0.0\n",
    "      ],\n",
    "      [\n",
    "        6.6, \n",
    "        0.725, \n",
    "        0.2, \n",
    "        3.29, \n",
    "        0.54, \n",
    "        9.2, \n",
    "        1.0,\n",
    "        1.0\n",
    "      ]\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "- Click **Send request**.\n",
    "\n",
    "- **Response** field on the right panel will show the result of the inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "493f4853-8d4b-4bf5-bbbc-b03819bd83b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Delete Your Serving Endpoint\n",
    "\n",
    "**🚨 : Please delete your serving endpoint after completing the above steps.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83e76120-f88e-41ee-9ebf-2a6f0c8aa8fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Getting Started with Mosaic AI AutoML\n",
    "\n",
    "In this lab, we will explore how **Mosaic AI AutoML** automates the process of model training, selection, and registration. \n",
    "\n",
    "_In the previous labs, you manually tracked and registered models using MLflow. In this one, you’ll see how AutoML automates those steps while still leveraging the same tracking infrastructure._\n",
    "\n",
    "AutoML allows you to build, train, and evaluate models with minimal code. We will create an AutoML experiment, inspect the results, register the best model, and transition it to the **Staging** stage.\n",
    "\n",
    "However, with the Databricks Free Edition, only Serverless compute is available and therefore only _Forecasting_ can be implemented for now and only using the UI.\n",
    "When using non-Serverless computes, other AutoML algorithms and features are available. \n",
    "\n",
    "![automl-create-experiment](./images/automl-create-experiment.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e27b19e4-8564-4f1e-86e7-f7bdcc75034c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Preprocess the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc3e664a-6749-4994-a2c5-2284be403b55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls(\"/databricks-datasets/COVID/covid-19-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e13de096-c171-42d0-9007-689ab0a6ba81",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755169334183}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "covid = spark.read.csv(\"/databricks-datasets/COVID/covid-19-data/us.csv\", sep=',', header=True, inferSchema=True)\n",
    "covid = covid.withColumn(\"date\", col(\"date\").try_cast(\"date\"))\n",
    "covid = covid.withColumn(\"cases\", col(\"cases\").cast(\"int\"))\n",
    "display(covid)\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS covid\")\n",
    "\n",
    "covid.write.saveAsTable(\"covid\")\n",
    "\n",
    "spark.table(\"covid\").printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d029684-bd88-4e7d-8958-3f94d4e42ed1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create and Run an AutoML Experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64d108d5-3932-4456-9b8f-b4a1f83d24b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "Let's initiate an AutoML experiment to construct a baseline model for predicting wine quality. The target field for this prediction will be the `quality` field.\n",
    "\n",
    "Follow these step-by-step instructions to create an AutoML experiment:\n",
    "\n",
    "- Navigate to **Experiments** under **Machine Learning** in the left sidebar menu.\n",
    "\n",
    "- Click on **Forcasting - Preview**.\n",
    "\n",
    "  ![automl-create-experiment-serverless](./images/automl-create-experiment-serverless.png)\n",
    "\n",
    "- Under the **Training data** section:\n",
    "\n",
    "  - To select the `covid` table as the input training data, select `Browse` under `Input training dataset` and navigate to the catalog and the same database we've been using (see **Classroom Setup** in this notebook). \n",
    "\n",
    "  - Specify **`date`** as the **Time Column**.\n",
    "\n",
    "  - Specify **`Daily`** as the **Forecasting frequency**.\n",
    "\n",
    "  - Specify **`7`** as the **Forecast horizon**.\n",
    "\n",
    "- Under the **Prediction** section:\n",
    "\n",
    "  - Specify **`cases`** as the **Target column**.\n",
    "\n",
    "  - Specify **`workspace.default`** as the **Prediction data path**\n",
    "\n",
    "  - Specify **`covid_forecast`** as the **Table name**\n",
    "\n",
    "- Under the **Model registration** section:\n",
    "\n",
    "  - Specify **`workspace.default`** as the **Register to location**\n",
    "\n",
    "  - Specify **`covid_model`** as the **Model name**\n",
    "\n",
    "- Under the **Advanced options** section:\n",
    "\n",
    "  - Specify **`SDAPE`** as the **Primary metric**.\n",
    "\n",
    "  - Specify **`10`** as the **Timeout (minutes)**\n",
    "\n",
    "- Click on **Start training**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba82f054-6730-4864-a1d0-1ee5fe70be09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Inspection of the Experiement\n",
    "\n",
    "Once the experiment is finished, it's time to examine the best run:\n",
    "\n",
    "- Access the completed experiment in the **Experiments** section.\n",
    "\n",
    "- Identify the best model run by evaluating the displayed **metrics**. \n",
    "\n",
    "Metrics might not be displayed by default on the screen.\n",
    "\n",
    "There are different columns such as the framework used (e.g., Scikit-Learn, XGBoost), evaluation metrics (e.g., Accuracy, F1 Score), and links to the corresponding notebooks for each model. This allows you to make informed decisions about selecting the best model for your specific use case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a180ce25-821a-42d0-b25a-b7a90f5519f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "experiments = mlflow.search_experiments(\n",
    "    view_type = mlflow.entities.ViewType.ACTIVE_ONLY, \n",
    "    filter_string = f\"name LIKE '/Users/{current_username}/databricks_automl/cases_covid_%'\", \n",
    "    order_by = [\"creation_time DESC\"],\n",
    "    max_results = 1,\n",
    ")\n",
    "experiment = experiments[0]\n",
    "\n",
    "print(f\"Exepriment URL: {workspace_url}/ml/experiments/{experiment.experiment_id}\")\n",
    "\n",
    "print(f\"Experiment id: {experiment.experiment_id}\")\n",
    "print(f\"Experiment Artifact Location: {experiment.artifact_location}\")\n",
    "# print(f\"Tags: {experiment.tags}\")\n",
    "print(f\"Experiment Lifecycle stage: {experiment.lifecycle_stage}\")\n",
    "print(f\"Experiment Creation timestamp: {experiment.creation_time}\")\n",
    "\n",
    "print(f\"Exepriment Registered Model URL: {workspace_url}/explore/data/models/{experiment.tags.get('_databricks_automl.output_model_name').replace('.', '/')}\")\n",
    "\n",
    "display(experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92da4173-6e09-4abc-9cfe-fc7ea7125847",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Inspection of the \"Best\" Experiement Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d0be498-ca0c-450e-bc39-829a289ad1e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs(\n",
    "    experiment_ids= [experiment.experiment_id], \n",
    "    run_view_type = mlflow.entities.ViewType.ACTIVE_ONLY, \n",
    "    order_by = [\"metrics.val_smape ASC\"], \n",
    "    max_results = 1,\n",
    "    output_format = 'list'\n",
    ")\n",
    "run = runs[0]\n",
    "\n",
    "print(f\"Best Experiement Run URL: {workspace_url}/ml/experiments/{experiment.experiment_id}/runs/{run.info.run_id}\")\n",
    "print(f\"Best Experiement Run id: {run.info.run_id}\")\n",
    "print(f\"Best Experiement Run SMAPE: {run.data.metrics['val_smape']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14c00577-94df-4a0a-9da7-17ed07567134",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Inspect the genreated inference notebook\n",
    "\n",
    "The AutoML process will provide access to a bacth inference notebook that you can access using the url generated by the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7184efe7-9c98-4a33-acfd-c40e05c7e91d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Exepriment Batch Inference Notebook URL: {workspace_url}/editor/notebooks/{experiment.tags.get('_databricks_automl.batch_inference_notebook_id')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01eee7a1-2d3b-47c2-9e3d-40429bc9d5a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Use the model for forecasting\n",
    "You can use the commands in this section with Databricks Runtime for Machine Learning 10.0 or above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e0f456c-013b-414e-a952-91585b947a2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load the model with MLflow\n",
    "\n",
    "MLflow allows you to easily import models back into Python by using the AutoML run_id.\n",
    "\n",
    "You should check and install the model requirements using the follwoing code:\n",
    "\n",
    "```\n",
    "requirements = mlflow.pyfunc.get_model_dependencies(model_uri)\n",
    "%pip install -r {requirements}\n",
    "dbutils.library.restartPython()\n",
    "```\n",
    "But this require the otebook to restart so we have included the dependencies at the begining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abbdbd08-76e3-4796-926e-b84312ecec6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_uri = \"runs:/{run_id}/model\".format(run_id=run.info.run_id)\n",
    "pyfunc_model = mlflow.pyfunc.load_model(model_uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21eb8bfa-1e75-4d41-9f03-388e31ba118f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Use the model to make forecasts\n",
    "\n",
    "Call the `predict_timeseries` model method to generate forecasts.    \n",
    "In Databricks Runtime for Machine Learning 10.5 or above, you can set `include_history=False` to get the predicted data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb8e71f8-8249-4db0-89d5-8f22a49e8adf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "time_column = \"date\"\n",
    "history_table = \"covid\"\n",
    "target_column = \"cases\"\n",
    "\n",
    "history_df = spark.table(history_table)\n",
    "history_df = history_df.withColumn(time_column, F.to_timestamp(time_column))\n",
    "history_df = history_df.orderBy(time_column, ascending=False).limit(30).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07598dc8-594b-409c-b3fa-58a35d715505",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755438814211}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "forecasts = pyfunc_model._model_impl.python_model.predict_timeseries()\n",
    "forecasts = forecasts.rename(columns={'yhat': target_column})\n",
    "forecasts = forecasts.rename(columns={'ds': time_column})\n",
    "forecasts = forecasts.sort_values(by=time_column, ascending=False).head(30)\n",
    "display(forecasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "393b6b29-26fb-4480-8f8f-7a35a0737b3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Plot the forecasted points\n",
    "\n",
    "In the plot below, the thick black line shows the time series dataset, and the blue line is the forecast created by the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba844b94-b960-4c0a-b7e7-5a0fc4d38531",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# fig = plt.figure(facecolor='w', figsize=(10, 6))\n",
    "# ax = fig.add_subplot(111)\n",
    "# forecasts = pyfunc_model._model_impl.python_model.predict_timeseries(include_history=True)\n",
    "\n",
    "\n",
    "\n",
    "# Code for plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the solid line for the historical datapoints.\n",
    "plt.plot(history_df[time_column], history_df[target_column], linestyle='-', marker='s', label='Historical values')\n",
    "\n",
    "# Plot the dashed line for the forecasted values\n",
    "plt.plot(forecasts[time_column], forecasts[target_column], linestyle='--', marker='o', label='Forecasts')\n",
    "\n",
    "# Set proper ticks on x-axis.\n",
    "tick_positions = pd.date_range(start=history_df[time_column].min(), end=forecasts[time_column].max(), periods=10)\n",
    "plt.xticks(tick_positions, labels=[date.strftime(\"%Y-%m-%d %H:%M\") for date in tick_positions], rotation=45)\n",
    "\n",
    "# Adding labels and legend\n",
    "plt.title('Recent Historical Data and Forecasts')\n",
    "plt.xlabel(time_column)\n",
    "plt.ylabel(target_column)\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Get Started with Databricks for Machine Learning",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
